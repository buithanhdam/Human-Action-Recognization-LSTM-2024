# Human-Action-Recognization-LSTM--2024
[Dam Thanh | Novice | Kaggle](https://www.kaggle.com/damthanh)
## The first uses two datasets, UCF101 and HMDB51, and is used through a machine learning technology named Kaggle, which can use Jupiter notebooks to program and use the data sets for free without downloading.
- UCF101: https://www.kaggle.com/datasets/pevogam/ucf101/data and video file list : https://www.kaggle.com/datasets/damthanh/ucf101-videolist/data
-	HMDB51: https://www.kaggle.com/datasets/damthanh/hmdb51full/data

## Method 1 (using a personal computer):
- First you need to access the path to the data set on kaggle through kaggle as on the two datasets already contained video folder, label file, video file list.
  * or can download two datasets from its official site that need to be processed to get the video list file (file code: extract-video-file-list-30-action)
- After downloading the data set we will have all the necessary files and put together with the file source code
  ![image](https://github.com/buithanhdam/Human-Action-Recognization-LSTM-2024/assets/76465481/dfec1e1c-86cc-41fa-af89-328d41b80447)

- Change the path in the source code file from kaggle/input according to the current lead of the data.

## Method 2 (using through kaggle):
- Continue using the notebook via kaggle first access kaggle, then press the Create -> New Notebooks button, then click File -> import notebook -> select the source code you want to use for kaggle to proceed to update the notebook
  * Default when importing the notebook the Input of the notebook already has the data of the UCF101 or HMDB51 dataset ready
  * If there is no Input then in the Notebook section on the right click Add Input and select the data from the kaggle dataset paths above to add
